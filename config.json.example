{
  "github": {
    // GitHub repository configuration
    "repository_url": "https://github.com/your-org/your-repo.git",
    "branch": "main",                    // Target branch (optional, defaults to main/master)
    "clone_depth": 1,                    // Shallow clone depth for faster processing
    "cleanup_after_processing": true,    // Delete temp files after processing
    "token": null                        // GitHub token for private repos (optional)
  },
  
  // EMBEDDING PROVIDER SELECTION
  "embedding_provider": "azure_openai",     // Options: "azure_openai", "mistral_ai", "sentence_transformers"
  
  "azure_openai": {
    // Azure OpenAI embedding service configuration
    "api_key": "your-azure-openai-api-key-here",
    "endpoint": "https://your-resource.openai.azure.com/",
    "deployment_name": "text-embedding-3-large",  // Available: text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large
    "api_version": "2024-02-01"
  },
  
  "mistral_ai": {
    // Mistral AI embedding service configuration
    "api_key": "your-mistral-api-key-here",
    "model": "codestral-embed",            // Options: "mistral-embed" (1024 dim), "codestral-embed" (1536 dim)
    "output_dimension": 1536,              // For codestral-embed: 1536 (default) up to 3072
    "api_base": "https://api.mistral.ai/v1"
  },
  
  "sentence_transformers": {
    // Sentence Transformers (Local) embedding configuration
    "model": "intfloat/multilingual-e5-large",  // Options: "sentence-transformers/all-MiniLM-L6-v2" (384 dim), "intfloat/multilingual-e5-large" (1024 dim)
    "vector_size": 1024                    // Must match model: all-MiniLM-L6-v2=384, multilingual-e5-large=1024
  },
  
  "qdrant": {
    // Qdrant vector database configuration
    "url": "https://your-cluster-id.region.cloud.qdrant.io:6333",
    "api_key": "your-qdrant-api-key-here",
    "collection_name": "your-collection-name",
    "vector_size": 3072,                 // Must match embedding model dimensions (see table below)
    "distance": "Cosine",                // Available: Cosine, Euclidean, Dot
    "vector_name": null,                 // VECTOR NAMING: null/empty = unnamed vectors (default), "model-name" = named vectors (for MCP compatibility)
    "recreate_collection": false         // WARNING: true will delete existing collection!
  },
  
  "processing": {
    // Document processing and chunking settings
    "chunk_size": 1000,                  // Characters per chunk (recommended: 500-2000)
    "chunk_overlap": 200,                // Overlap between chunks for context continuity
    "markdown_extensions": [".md", ".markdown", ".mdown", ".mkd"],
    "exclude_patterns": ["node_modules", ".git", "__pycache__", "*.pyc", ".DS_Store"],
    
    // OPTIMIZED DEDUPLICATION SETTINGS
    "deduplication_enabled": true,       // Enable/disable duplicate removal
    "similarity_threshold": 0.95,        // Higher = more strict (0.9-0.98 recommended)
    
    // EMBEDDING GENERATION SETTINGS (OPTIMIZED)
    "embedding_batch_size": 50,          // Chunks per batch (optimized for Azure OpenAI)
    "max_retries": 3,                    // Retries for rate limit errors
    "batch_delay_seconds": 1             // REQUIRED: Delay between batches to avoid Azure 429 errors
  },
  
  "output": {
    // Local file output settings (for generated markdown)
    "base_directory": "markdown",
    "combined_filename": "__combined_markdown.md",
    "preserve_structure": true
  },
  
  "logging": {
    // Logging configuration
    "level": "INFO",                     // DEBUG, INFO, WARNING, ERROR
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  }
}

/*
USAGE EXAMPLES:

1. Basic usage with config file:
   python3 github_to_qdrant.py config.json.example

2. Override repository URL:
   python3 github_to_qdrant.py config.json.example --repo-url https://github.com/different/repo.git

PROVIDER-SPECIFIC SETUP:

For Azure OpenAI:
1. Set embedding_provider to "azure_openai"
2. Configure azure_openai section with your API key and endpoint
3. Set vector_size to match your model (1536 or 3072)

For Mistral AI:
1. Set embedding_provider to "mistral_ai" 
2. Configure mistral_ai section with your API key
3. Set vector_size to match output_dimension (1536 or 3072)

For Sentence Transformers (Local):
1. Set embedding_provider to "sentence_transformers"
2. Choose model: "sentence-transformers/all-MiniLM-L6-v2" or "intfloat/multilingual-e5-large"
3. Set vector_size to match model dimensions (384 or 1024)
4. Install: pip install sentence-transformers
5. Vector naming options:
   - vector_name: null or omit entirely → Creates unnamed/default vectors (standard)
   - vector_name: "model-name" → Creates named vectors (for MCP servers)

PERFORMANCE NOTES:
- embedding_batch_size=50: Optimized for Azure OpenAI (2.5x faster than default 20)
- batch_delay_seconds=1: REQUIRED to prevent Azure OpenAI rate limit errors
- similarity_threshold=0.95: Removes near-duplicates while preserving unique content
- deduplication uses optimized vectorized operations (5-15x faster than old method)

EMBEDDING MODEL DIMENSIONS:
Azure OpenAI:
- text-embedding-ada-002: 1536 dimensions
- text-embedding-3-small: 1536 dimensions  
- text-embedding-3-large: 3072 dimensions (recommended for best quality)

Mistral AI:
- mistral-embed: 1024 dimensions (general text)
- codestral-embed: 1536 dimensions (default) up to 3072 (code-specialized, recommended for technical docs)

Sentence Transformers (Local):
- sentence-transformers/all-MiniLM-L6-v2: 384 dimensions (lightweight, fast)
- intfloat/multilingual-e5-large: 1024 dimensions (multilingual, high quality)

BENEFITS BY PROVIDER:
Azure OpenAI: Best quality, latest models, enterprise support
Mistral AI: Code-specialized models, competitive pricing, European provider
Sentence Transformers: No API costs, privacy (local processing), no rate limits, offline capable

VECTOR NAMING EXPLAINED:
Default/Unnamed Vectors (vector_name: null):
- Standard Qdrant behavior - vectors stored without specific names
- Compatible with most Qdrant clients and applications
- Simpler configuration and usage

Named Vectors (vector_name: "model-name"):
- Required for MCP (Model Context Protocol) servers
- Allows multiple embedding models in same collection
- Vector name should match the embedding model identifier

SECURITY:
- Never commit API keys to version control
- Use environment variables or secure key management
- Keep GitHub tokens private for private repositories
*/